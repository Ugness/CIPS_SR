{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659ce409-c2da-4a12-aed5-ff5e04346a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1bc44e-7080-424d-88e3-af50e9eedb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'fid/pretrained_256'\n",
    "target_dir = 'fid/pretrained_256_64_output'\n",
    "target_size = 64\n",
    "os.makedirs(target_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f1388d-42e6-4def-8793-70096d2bf341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [03:26<00:00, 241.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(source_dir)):\n",
    "    img = Image.open(os.path.join(source_dir, i))\n",
    "    img_resize = img.resize((target_size, target_size), Image.LANCZOS)\n",
    "    img_resize.save(os.path.join(target_dir, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed118ad-24b0-42a7-8dc8-b8fbcf784956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93224a35-8489-4441-bae5-0d934012fb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216bb62b-048b-41f0-a30b-ed2338b01e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_fidelity import calculate_metrics\n",
    "import torchvision\n",
    "from dataset import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a1bdd3-adcb-4827-b341-6f059ec8beee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial dataset length 126227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frechet_inception_distance': 10.622593557610315}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_fid = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Lambda(lambda x: x.mul_(255.).byte())])\n",
    "dataset = ImageDataset(f'LSUN/church_train_lmdb/{target_size}', transform=transform_fid, resolution=target_size, to_crop=False)\n",
    "print('initial dataset length', dataset.length)\n",
    "dataset.length = len(os.listdir(target_dir))\n",
    "    \n",
    "calculate_metrics(target_dir, dataset, cuda=True, isc=False, fid=True, kid=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16d1b4-8804-4371-ac2a-df2a76247165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fefa73-e53d-4f87-9de4-794c263f5d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a57539d-a2e5-4004-a3bf-f7bcd576093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'fid/CIPS-64'\n",
    "target_dir = 'fid/CIPS-64-256-output'\n",
    "target_size = 256\n",
    "os.makedirs(target_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29069ae4-bb67-4361-bf8f-5d11650e2868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [16:44<00:00, 49.78it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(source_dir)):\n",
    "    img = Image.open(os.path.join(source_dir, i))\n",
    "    img_resize = img.resize((target_size, target_size), Image.LANCZOS)\n",
    "    img_resize.save(os.path.join(target_dir, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6faeefa-250a-48b7-8ef9-44eb8b91dcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial dataset length 126227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frechet_inception_distance': 65.5256698946882}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_fid = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Lambda(lambda x: x.mul_(255.).byte())])\n",
    "dataset = ImageDataset(f'LSUN/church_train_lmdb/{target_size}', transform=transform_fid, resolution=target_size, to_crop=False)\n",
    "print('initial dataset length', dataset.length)\n",
    "dataset.length = len(os.listdir(target_dir))\n",
    "    \n",
    "calculate_metrics(target_dir, dataset, cuda=True, isc=False, fid=True, kid=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "824dc012-55a5-4062-bcb7-9a058b669ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'fid/CIPS-SR-64'\n",
    "target_dir = 'fid/CIPS-SR-64-256-output'\n",
    "target_size = 256\n",
    "os.makedirs(target_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b977408-3c6a-4f65-8618-e244c3f71286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [17:23<00:00, 47.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(source_dir)):\n",
    "    img = Image.open(os.path.join(source_dir, i))\n",
    "    img_resize = img.resize((target_size, target_size), Image.LANCZOS)\n",
    "    img_resize.save(os.path.join(target_dir, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ddb94d-d75c-4842-9b2c-5e1d1068f4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial dataset length 126227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frechet_inception_distance': 66.3697289958908}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_fid = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Lambda(lambda x: x.mul_(255.).byte())])\n",
    "dataset = ImageDataset(f'LSUN/church_train_lmdb/{target_size}', transform=transform_fid, resolution=target_size, to_crop=False)\n",
    "print('initial dataset length', dataset.length)\n",
    "dataset.length = len(os.listdir(target_dir))\n",
    "    \n",
    "calculate_metrics(target_dir, dataset, cuda=True, isc=False, fid=True, kid=False, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
